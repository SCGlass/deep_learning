{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab CNN\n",
    "\n",
    "Create a CNN that can classify flower types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importing relevant packages for pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import kerastuner as kt\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre processing the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path(\"Data/flowers\") # Setting directory path as a variable for the flowers data set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count =len(list(data_dir.glob(\"*/*.jpg\"))) # Doing an image count to check the amount of images within the dataset\n",
    "image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(data_dir.glob(\"*/*.jpg\"))[0:2] # Listing some of the images, This is instance [0:2] is the first folder and first 2 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking to see if the images get displayed\n",
    "sunflower = list(data_dir.glob(\"sunflower/*\"))\n",
    "PIL.Image.open(str(sunflower[0])) # checking first image in sunflower folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and splitting the data set using keras utilities  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will have a few parameters that can change within the function these will include batch size, image width and height\n",
    "# I will split the data in to a train at 80% and test 20%\n",
    "\n",
    "def train_test_split(batch_size, img_width, img_height):\n",
    "\n",
    "    train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        data_dir,\n",
    "        validation_split = 0.2,\n",
    "        subset = \"training\",\n",
    "        seed = 123,\n",
    "        image_size = ( img_height,img_width),\n",
    "        batch_size = batch_size,)\n",
    "\n",
    "    \n",
    "    test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        data_dir,\n",
    "        subset = \"validation\",\n",
    "        validation_split=0.2,\n",
    "        seed = 123,\n",
    "        image_size = ( img_height, img_width),\n",
    "        batch_size = batch_size,)\n",
    "\n",
    "    return train_ds, test_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, test_ds = train_test_split(64,64,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need to also add class names so that the data has labels\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12,14))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range (12):\n",
    "        ax = plt.subplot(4,3, i +1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        \n",
    "        \n",
    "\n",
    "        plt.title(class_names[labels[i]])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also did  visual check through the picture files to see if there were any files that stood out and were not so suitable to train on. I will show some examples below.\n",
    "\n",
    "This would not always be possible on huge datasets as it takes some time to go through every picture. However as it was small I thought it was appropriate to show some examples.\n",
    "\n",
    "Some images seemed to have no flowers in them at all so these were obvious. Others may of been too  many varieties of flowers in one picture.\n",
    "\n",
    "I decided that this would be the best approach as when training a model you want to have clean relevant data for it to be trained on.\n",
    "\n",
    "The picture size has been set to 64 X 64 with a batch size of 64. These reason I made the pictures this small was so that the data would be trained on quicker. Due to the fact that my computer is not the most powerful! You can see however that the pictures are fairly recognizable to the human eye even though they are pixelated. The catch size was set at 64 as this is the extent of the memory for my computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_data_dir = data_dir = pathlib.Path(\"Data/bad_data\")\n",
    "\n",
    "bad_data = tf.keras.utils.image_dataset_from_directory(\n",
    "            bad_data_dir,\n",
    "            validation_split = 0.2,\n",
    "            subset = \"training\",\n",
    "            seed = 123,\n",
    "            image_size = ( 64,64),\n",
    "            batch_size = 64,)\n",
    "\n",
    "plt.figure(figsize=(12,14))\n",
    "for images, labels in bad_data.take(1):\n",
    "    for i in range (12):\n",
    "        ax = plt.subplot(4,3, i +1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        \n",
    "        \n",
    "\n",
    "        plt.title(class_names[labels[i]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_ds_to_numpy_array(train_ds, test_ds):\n",
    "    \n",
    "    train_images = []\n",
    "    train_labels = []\n",
    "    for batch in train_ds.as_numpy_iterator():\n",
    "        train_images.append(batch[0])\n",
    "        train_labels.append(batch[1])\n",
    "\n",
    "    test_images = []\n",
    "    test_labels = []\n",
    "    for batch in test_ds.as_numpy_iterator():\n",
    "        test_images.append(batch[0])\n",
    "        test_labels.append(batch[1])\n",
    "\n",
    "    train_images = np.concatenate(train_images)\n",
    "    train_labels = np.concatenate(train_labels)\n",
    "    test_images = np.concatenate(test_images)\n",
    "    test_labels = np.concatenate(test_labels)\n",
    "\n",
    "    print(f\"Train Images shape:\", {train_images.shape})\n",
    "    print(f\"Train Labels Shape:\" ,{train_labels.shape})\n",
    "    print(f\"Number of Train Samples:\", {len(train_images)})\n",
    "    print(f\"Number of Train labels:\" ,{len(train_labels)})\n",
    "\n",
    "    print(f\"Test Images shape:\", {test_images.shape})\n",
    "    print(f\"Test Labels Shape:\" ,{test_labels.shape})\n",
    "    print(f\"Number of Test Samples:\", {len(test_images)})\n",
    "    print(f\"Number of Test labels:\", {len(test_labels)})\n",
    "\n",
    "    return train_images, train_labels, test_images, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the function with batchsize 32, height 180 and 180\n",
    "train_images, train_labels, test_images, test_labels =  keras_ds_to_numpy_array(train_ds, test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to use keras tuner to help find the best hyper parameters for my model. First i have to build a function that will have the different parameters that i will try to build the best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 64\n",
    "img_width = 64\n",
    "\n",
    "def model_builder(hp):\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)))\n",
    "\n",
    "    # input layer \n",
    "    model.add(layers.Conv2D(\n",
    "        filters=hp.Int(\"input_filters\", min_value=32, max_value=256, step=32),\n",
    "        kernel_size=3,\n",
    "        activation=\"relu\",\n",
    "        padding=\"same\",\n",
    "        input_shape=(img_height, img_width, 3)\n",
    "    ))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    # convolution network layers : I will use a for loop that will determine what the best amount of layers will be for the model using the keras tuner\n",
    "    for i in range(hp.Int(\"n_conv_layers\", 1,4)):\n",
    "        model.add(layers.Conv2D(\n",
    "            filters=hp.Int(f\"conv_{i}_filters\", min_value=32, max_value=256, step=32),\n",
    "            kernel_size=3,\n",
    "            activation=\"relu\",\n",
    "            padding=\"same\")\n",
    "        )\n",
    "        model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    for i in range(hp.Int(\"n_dense_layers\", 1,4)):\n",
    "        model.add(layers.Dense(\n",
    "            units=hp.Choice(f\"n_nodes_{i}\", values= [10, 20, 50, 100]), #changed these to small values\n",
    "            activation=\"relu\")\n",
    "        )\n",
    "        \n",
    "    model.add(layers.Dense(5)) # maybe make it more scalable\n",
    "    model.add(layers.Activation(\"softmax\"))\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp.Choice(\"learning_rate\", values=[1e-2, 1e-3, 1e-4])),\n",
    "                  loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "                  metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will now explain why I chose these parameters to search and the reason behind my model architecture: \n",
    "\n",
    "- \"Sequential\" - I chose a sequential model as CNN picture analysis is a sequenced process and based on a one input tensor one output tensor system. \n",
    "\n",
    "- \"Rescaling\" - I rescaled the images within the model. This ensures that the values of the pictures are between 0 and 1. This makes it easier for the deep learning model to make predictions as everything is between 0 and 1.\n",
    "\n",
    "- \"Convolution Layers\" - The first convolution layer is the input layer. This is determind by the size of the input. Using the tuner parameter helps me determine how many filters should be applied. The following layers are then put through the tuner to see how many layers and how many filter work best for validation accuracy. The layer results could be between 1 and 4 \n",
    "\n",
    "- \"kernel  size\" is then set to a 3 X 3. This means that every filter passes over the image with a 3 X 3 grid. I chose 3 X 3 as it is very common to use and as the pictures are at 64 X 64 if I had any higher it may miss vital information within the picture. I kept the kernel size the same throughout the model. \n",
    "\n",
    "- \"Padding\" is added so that there is 0's surrounding the input. This helps so that the filter doesn't miss any information on the outer pixels of the image. It is set to same so that output size is the same size as the input size.\n",
    "\n",
    "- \"Activation\" \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now I have created my model structure it is time to do run the keras tuner to find the best hyper parameters for my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='tuner_results',\n",
    "                     project_name='flowers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(train_images, train_labels, epochs=50,validation_split=0.2, callbacks=[early_stopping])  #validation_split=0.2,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tuner.get_best_models(num_models=1)\n",
    "print(best_model[0].summary())\n",
    "\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(1)[0]\n",
    "print(best_hyperparameters.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now i will train my model with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(best_hyperparameters, epochs):\n",
    "\n",
    "    checkpoint_filepath = \"../best_model/checkpoint.model.keras\"\n",
    "    \n",
    "    model = tuner.hypermodel.build(best_hyperparameters)\n",
    "\n",
    "    early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_loss\",mode=\"min\", verbose=1, patience=3)\n",
    "    #h5py.ModelCheckpoint(\"best_model.h5\", monitor=\"val_loss\", mode=\"min\", save_best_only= True, verbose=1)\n",
    "    model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath, \n",
    "        monitor=\"val_accuracy\", \n",
    "        mode=\"max\", verbose=1, \n",
    "        save_best_only=True)\n",
    "    \n",
    "\n",
    "\n",
    "    history = model.fit(train_images,train_labels , epochs=epochs, validation_split=0.2, callbacks=[early_stopping, model_checkpoint])\n",
    "\n",
    "    test_loss, test_accuracy =model.evaluate(test_images, test_labels, verbose=0)\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "    plt.figure(figsize=(8,8))\n",
    "\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(history.history[\"accuracy\"], label=\"Training Accuracy\")\n",
    "    plt.plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
    "    plt.plot(history.history[\"val_loss\"], label=\"Validation Loss \")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    print(model.summary())\n",
    "    \n",
    "    return keras.models.load_model(checkpoint_filepath)\n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate_model(best_hyperparameters, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is noticeable that there is some over fitting within the model. The training accuracy is consistent in the way it continues to improve while the Validation drops out around 70 % accuracy. This can occur if the dta set is too small. I would like to try and improve this. I will try first to use Data augmentation. This adds additional training data by creating random differences od the original images. This is done by example zooming in and rotating. This will hopefully expose the model to more data and generalizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will now add this into my model function and see if it has any improvements. Then I will take the best model again and train that to see if the results are better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will test the new model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(epochs, img_width, img_height):\n",
    "    \n",
    "    model= keras.Sequential([\n",
    "        layers.Rescaling(1./255, input_shape=(img_width, img_height, 3)),\n",
    "\n",
    "        layers.Conv2D(128, (3,3), activation =\"relu\", padding=\"same\"),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "\n",
    "        layers.Conv2D(64, (3,3), activation =\"relu\", padding=\"same\"),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "\n",
    "        layers.Conv2D(160, (3,3), activation =\"relu\", padding= \"same\"),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "\n",
    "        layers.Conv2D(224, (3,3), activation =\"relu\", padding= \"same\"),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "\n",
    "        layers.Conv2D(224, (3,3), activation =\"relu\", padding= \"same\"),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "\n",
    "        layers.Flatten(),\n",
    "\n",
    "        layers.Dense(50, activation=\"relu\"),\n",
    "\n",
    "        layers.Dropout(0.5),\n",
    "\n",
    "        layers.Dense(5),\n",
    "\n",
    "        layers.Activation(\"softmax\")\n",
    "\n",
    "\n",
    "    ])\n",
    "\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate= 0.001),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    \n",
    "    early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=1, patience=3)\n",
    "    \n",
    "    checkpoint_filepath = \"../best_model/checkpoint.model.keras\"\n",
    "\n",
    "    model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath, \n",
    "        monitor=\"val_accuracy\", \n",
    "        mode=\"max\", verbose=1, \n",
    "        save_best_only=True\n",
    "    )\n",
    "\n",
    "    history = model.fit(train_images, train_labels, epochs=epochs, validation_split=0.2, callbacks=[early_stopping, model_checkpoint])\n",
    "\n",
    "    test_loss, test_accuracy = model.evaluate(test_images, test_labels, verbose=0)\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history[\"accuracy\"], label=\"Training Accuracy\")\n",
    "    plt.plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
    "    plt.plot(history.history[\"val_loss\"], label=\"Validation Loss \")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    print(model.summary())\n",
    "    \n",
    "    return keras.models.load_model(checkpoint_filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate_model(25, 64,64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
