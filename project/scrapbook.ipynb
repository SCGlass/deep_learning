{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spell_check_df = pd.DataFrame()\n",
    "spell_check_df[\"test_case\"] = df[\"test_case\"]\n",
    "spell_check_df[\"label_gold\"] = df[\"label_gold\"]\n",
    "spell_check_df[\"target_ident\"] = df[\"target_ident\"]\n",
    "\n",
    "spell_check_df[\"test_case\"] = df[\"test_case\"].apply(lambda x: ''.join(TextBlob(x).correct()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spell_check_df.to_csv(\"../project/Data/spellcheck.csv\", index=False)\n",
    "spell_check_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spell_check_df[\"test_case\"] = pd.DataFrame(spell_check_df.test_case.apply(clean_text))\n",
    "\n",
    "spell_check_df[\"test_case\"] = pd.DataFrame(spell_check_df.test_case.apply(clean_text))\n",
    "\n",
    "spell_check_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_with_emotion(row, aug):\n",
    "    original_text = row[\"test_case\"]\n",
    "    original_label = row[\"label_gold\"]\n",
    "    original_emotion = row[\"target_ident\"]\n",
    "\n",
    "    \n",
    "    augmented_text = aug.augment(original_text)\n",
    "    \n",
    "    # Create a new row with augmented text and the original emotion label\n",
    "    row[\"test_case\"] = augmented_text\n",
    "    row[\"label_gold\"] = original_label\n",
    "    row[\"target_ident\"] = original_emotion\n",
    "    \n",
    "    return row\n",
    "\n",
    "# Augmenter configuration\n",
    "aug = naw.ContextualWordEmbsAug(model_path='bert-base-uncased', action=\"insert\")\n",
    "\n",
    "# Apply the augmentation function to each row in the DataFrame\n",
    "augmented_df = df_non_hateful.apply(lambda row: augment_with_emotion(row, aug), axis=1)\n",
    "\n",
    "augmented_df['test_case'] = augmented_df[\"test_case\"].apply(lambda x: str(x).replace('[', '').replace(']', '').replace(\"'\", ''))\n",
    "\n",
    "augmented_df.to_csv(\"../project/Data/augmented.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_hateful_aug = pd.read_csv(\"../project/Data/augmented.csv\")\n",
    "df_non_hateful_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, \"test_case\"] = df[\"test_case\"].apply(preprocess_text)\n",
    "\n",
    "spell_check_df.loc[:, \"test_case\"] = spell_check_df[\"test_case\"].apply(preprocess_text)\n",
    "\n",
    "df_non_hateful_aug.loc[:, \"test_case\"] = df_non_hateful_aug[\"test_case\"].apply(preprocess_text)\n",
    "\n",
    "df, spell_check_df,"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
